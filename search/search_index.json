{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pathogen genomics","text":"<p>Please click the links below for practical materials:</p> <ul> <li>Module 5: Transcriptomics</li> <li>Module 6: Microbiome</li> <li>Module 7: GWAS</li> </ul>"},{"location":"gwas/","title":"Genome Wide Aassociation Studies (GWAS)","text":"<p>The objective of this tutorial is to get you familiar with the basic file format used for GWAS and common tools used for analysis and take you through data Quality control (Crucial in any study!). </p> <p>Our dataset is based on a GWAS study for Meningococcal disease in a European population (https://www.nature.com/articles/ng.640).</p> <p>Data  * Genome wide SNP data  * Scripts to facilitate analysis</p> <p>Software you will need for analysis   * Computer workstation with Unix/Linux operating system   * PLINK software for genome-wide association analysis: http://pngu.mgh.harvard.edu/_purcell/plink/download.shtml  * Statistical software for data analysis and graphing such as: R: http://cran.r-project.org/  * BCFtools</p> <p>The data for this practical is in the <code>~/Module7</code> directory. Please navigate to this directory before running any commands. </p>"},{"location":"gwas/#1-create-bed-files-for-analysis","title":"1. Create BED files for analysis","text":"<p>Convert your plink genotype files to binary format - smaller file easier for manipulation of data. </p> <p>We have already provided you with plink formatted files we won't have to do this step.</p> <p>Info</p> <p>plink allows for the conversion from many different formats to plink format. For example if you had a VCF file you could type: <pre><code>plink --vcf MD.vcf.gz --make-bed --out MD \n</code></pre></p> <p>Your data set:</p> <p>Plink binary formatted dataset consisting of 3004 individuals, 409 cases, 2595 controls, 601089 variants</p> <ul> <li>MD.bed \u2013 binary-coded information on individuals and variants</li> <li>MD.bim \u2013 variant information: \u201cChromosome\u201d, \u201cMarker name\u201d, \u201cGenetic Distance\u201d (or '0' as dummy variable), \u201cBase-pair coordinate\u201d, \u201cAllele 1\u201d, \u201cAllele 2\u201d. Each SNP must have two alleles.</li> <li>MD.fam \u2013 Individual Information. The first 6 columns are mandatory and in the order: \u201cFamily ID\u201d, \u201cIndividual ID\u201d, \u201cPaternal ID\u201d, \u201cMaternal ID\u201d, \u201cSex\u201d, \u201cPhenotype\u201d.</li> </ul> <p>Double-check the basic stats of your dataset (number of variants, individuals, controls, cases) by examining MD.bim and MD.fam with bash utilities like <code>awk</code> or <code>wc</code>. </p> <p>What other information is available?</p>"},{"location":"gwas/#2-sample-qc","title":"2. Sample QC","text":""},{"location":"gwas/#identification-of-individuals-with-discordant-sex-information","title":"Identification of Individuals with discordant sex information","text":"<p>Ideally, if X-chromosome data are available, we would calculate the mean homozygosity rate across X chromosome markers for each individual in the study and identify discordance with our reported Sex phenotype.</p> <p>As our data only contains autosomes we will skip this step.</p>"},{"location":"gwas/#identification-of-individuals-with-elevated-missing-data-rates-or-outlying-heterozygosity-rate","title":"Identification of individuals with elevated missing data rates or outlying heterozygosity rate","text":"<p>At the shell prompt type:  <pre><code>plink --bfile MD --missing --out MD\n</code></pre></p> <p>This creates the files MD.imiss (sample-based missing report) and MD.lmiss (variant-based missing report). The fourth column in the imiss file (N_MISS) gives the number of missing SNPs and the sixth column (F_MISS) gives the proportion of missing SNPs per individual. </p> <p>At the shell prompt type:</p> <pre><code>plink --bfile MD --het --out MD\n</code></pre> <p>This creates the file MD.het where the third column gives the observed number of homozygous genotypes [O(Hom)] and the fifth column gives the number of non-missing genotypes [N(NM)], per individual. </p> <p>Calculate the observed heterozygosity rate per individual using the formula (N(NM) - O(Hom))/N(NM) and create a graph where the proportion of missing SNPs per individual is plotted on the x-axis and the observed heterozygosity rate per individual is plotted on the y-axis. Type: </p> <pre><code>R CMD BATCH imiss-vs-het.Rscript\n</code></pre> <p>This creates the graph MD.imiss-vs-het.pdf (see below). </p> <p></p> <p>Info</p> <p>Examine the plot to decide reasonable thresholds at which to exclude individuals based on elevated missing or extreme heterozygosity. </p> <p>Here we will exclude all individuals with a genotype failure rate \u2265 0.0185 (vertical dashed line) and/or heterozygosity rate \u00b1 3 standard deviations from the mean (horizontal dashed lines). </p> <p>Add the family ID and individual ID of all the failing this QC using:</p> <pre><code>R CMD BATCH imiss_het_fail.Rscript\n</code></pre> <p>This produces a file named fail_imiss_het_qc.txt </p> <p>Question</p> <p>How many samples failed this QC stage? </p>"},{"location":"gwas/#identification-of-duplicated-or-related-individuals","title":"Identification of duplicated or related individuals","text":"<p>To identify duplicate &amp; related individuals, create an Identity-by-State (IBS) matrix \u2013 calculated for each pair of individuals based on the shared proportion of alleles. </p> <p>To reduce the computational complexity, first prune the dataset so that no pair of SNPs (within a given window e.g 200kb) has linkage disequilibrium (r\u00b2 &gt; 0.2). Type </p> <pre><code>plink --bfile MD --indep-pairwise 200 5 0.5 --out MD\n</code></pre> <p>This creates files with the extension .prune.in .prune.out &amp; *.log. Then, to extract pruned SNPs and generate pair-wise IBS, type: </p> <pre><code>plink --bfile MD --extract MD.prune.in --genome --out MD \n</code></pre> <p>This might take a few minutes and creates files with the extension .genome &amp; .log </p> <p>Info</p> <p>You can also create a BED file with the pruned SNPs: <code>plink --bfile MD --extract MD.prune.in --make-bed --out MD.pruned</code>. Note: <code>nohup</code> and <code>&amp;</code> are used to allow the command to run in the background thus freeing up the terminal for further use. You can use top to see if the process is still running (remember to press q to exit). Alternatively, you could of course simply run the command in another terminal. </p> <p>Question</p> <p>How many SNPs are in your pruned list? HINT: Have a look at your log file (using the <code>less</code> command) or type <code>wc -l MD.prune.in</code></p> <p>To identify all pairs of individuals with an Idenity-by-descent (IBD) &gt; 0.185. Type: </p> <pre><code>perl run-IBD-QC.pl MD\n</code></pre> <p>Info</p> <p>The code also looks at the individual call rates stored in MD.imiss and outputs the ID of the individual with the lower call rate to fail_IBD-QC.txt for each pair of related individuals. </p> <p>To visualise the IBD rates, type: </p> <pre><code>R CMD BATCH  plot-IBD.Rscript\n</code></pre> <p>This generates MD.IBD-hist.pdf </p> <p></p> <p>Info</p> <p>Note: The expectation is that IBD = 1 for duplicates or monozygotic twins, IBD = 0.5 for 1st-degree relatives, IBD = 0.25 for 2nd-degree relatives and IBD = 0.125 for 3rd-degree relatives. Due to variation around these values it is typical to exclude one individual from each pair with an IBD &gt; 0.185, which is halfway between the expected IBD for 3rd- and 2nd-degree relatives. </p>"},{"location":"gwas/#identification-of-individuals-of-divergent-ancestry","title":"Identification of individuals of divergent ancestry","text":"<p>In the interest of time, this step has been mostly done for you.</p> <p>Principal components analysis (PCA) is performed with pruned bed file datasets generated before using the ./RUN_PCA.sh command. This generates the following output files: MD.pruned.pca.par, MD.pruned.pca.log, MD.pruned.pca.evec, MD.pruned.pca, MD.pruned.eval. The evec extension file is what you will need to view your PCs</p> <p>Create a scatter diagram of the first two principal components, including all individuals in the file MD.pruned.pca.evec (the first and second PCs are columns 2 and 3 respectively). Type: </p> <pre><code>R CMD BATCH plot-pca-results.Rscript\n</code></pre> <p>This outputs pca_plot.pdf</p> <p></p> <p>Info</p> <p>Data in column 4 is used to colour the points according to phenotype (i.e. case vs control). Here, we chose to exclude all individuals with a 2nd principal component score &gt;0.07. </p> <pre><code>R CMD BATCH write_pca_fail.R\n</code></pre> <p>To write the FID and IID of the filtered individuals to a file called fail_pca.txt. </p> <p>Question</p> <p>How many individuals failed the PCA threshold? </p>"},{"location":"gwas/#remove-all-individuals-failing-qc","title":"Remove all individuals failing QC","text":"<p>To concatenate all the files listing individuals failing the previous QC steps into single file, at the unix prompt type: </p> <pre><code>cat fail*txt | sort -k1 | uniq &gt; fail_qc_inds.txt\n</code></pre> <p>The file fail_qc_inds.txt should now contain a list of unique individuals failing the previous QC steps. </p> <p>To remove these from the dataset type: </p> <pre><code>plink --bfile MD --remove fail_qc_inds.txt --make-bed --out clean.MD\n</code></pre> <p>Question</p> <p>How many individuals in total will be excluded from further analysis?</p> <p>How many individuals in total do you have for further analysis? HINT: check your log file</p>"},{"location":"gwas/#marker-qc","title":"Marker QC","text":""},{"location":"gwas/#identify-all-markers-with-an-excessive-missing-data-rate","title":"Identify all markers with an excessive missing data rate","text":"<p>To calculate the missing genotype rate for each marker type: </p> <pre><code>plink --bfile clean.MD --missing --out clean.MD\n</code></pre> <p>The results of this analysis can be found in clean.MD.lmiss. </p> <p>Plot a histogram of the missing genotype rate to identify a threshold for extreme genotype failure rate. This can be done using the data in column five of the clean.MD.lmiss file. Type: </p> <pre><code>R CMD BATCH lmiss-hist.Rscript\n</code></pre> <p>This generates clean.MD.lmiss.pdf </p> <p></p> <p>We chose to a call-rate threshold of 5% (these SNPs will be removed later in the protocol). </p>"},{"location":"gwas/#test-markers-for-different-genotype-call-rates-between-cases-and-contols","title":"Test markers for different genotype call rates between cases and contols","text":"<p>To test all markers for differences in call rate between cases and controls, at the Unix prompt type: </p> <pre><code>plink --bfile clean.MD --test-missing --allow-no-sex --out clean.MD\n</code></pre> <p>The output of this test can be found in clean.MD.missing. </p> <p>To create a file called \u2018fail-diffmiss-qc.txt\u2019, which contains all SNPs with a significantly different (P&lt;0.00001) missing rate between cases and controls, type </p> <pre><code>perl run-diffmiss-qc.pl clean.MD\n</code></pre> <p>Question</p> <p>How many variants have failed QC? </p>"},{"location":"gwas/#remove-all-markers-failing-qc","title":"Remove all markers failing QC","text":"<p>To remove poor SNPs from further analysis and create a new clean (QC\u2019D) MD data file, at the Unix prompt type:</p> <pre><code>plink --bfile clean.MD --exclude fail-diffmiss-qc.txt --maf 0.01 --geno 0.05 --hwe 0.00001 --make-bed --out clean.final.MD\n</code></pre> <p>In addition to markers failing previous QC steps, those with a MAF &lt; 0.01, missing rate &gt; 0.05 and a HWE P-value &lt; 0.00001 (in controls) are also removed. </p> <p>Question</p> <p>How many variants and individuals pass filters and QC for your GWAS? </p>"},{"location":"gwas/#perform-a-gwas-on-your-qcd-dataset","title":"Perform a GWAS on your QC\u2019d dataset","text":"<p>To run a basic case/control association test, at the unix prompt type:</p> <pre><code>plink --bfile clean.final.MD --assoc --ci 0.95 --adjust --allow-no-sex --out final.MD.assoc\n</code></pre> <p>Your association output file will contain 12 columns: </p> <ul> <li>CHR - Chromosome</li> <li>SNP - SNP ID</li> <li>BP - Physical position (base-pair)</li> <li>A1 - Minor allele name (based on whole sample)</li> <li>F_A - Frequency of this allele in cases</li> <li>F_U - Frequency of this allele in controls</li> <li>A2 - Major allele name</li> <li>CHISQ - Basic allelic test chi-square (1df)</li> <li>P - Asymptotic p-value for this test</li> <li>OR - Estimated odds ratio (for A1, i.e. A2 is reference)</li> <li>L95 - Lower bound of 95% confidence interval for odds ratio</li> <li>U95 - Upper bound of 95% confidence interval for odds ratio</li> </ul> <p>To visualise your data:</p> <p>Generate a Quantile-Quantile (QQ) plot of your p-values to look at the distribution of P-values and assess whether genomic inflation is present (lambda&gt;1) (this can also be found in your assoc. log file).</p> <p>Generate a manhattan plot to visualise where your association signals lie across the chromosomes. Type: </p> <pre><code>R CMD BATCH GWAS_plots.R\n</code></pre> <p>This generates both plots: final.MD.assoc_qq.png and final.MD.assoc_mhplot.png </p> <p></p> <p>Question</p> <p>What do the plots tell you? </p> <p>Let\u2019s zoom into a region of interest: the tower of SNPs on CHR1 (coloured in yellow). This the Complement Factor H (CFH) region known to be associated with Meningococcal disease. The previous Rscript in 8.2.2 above also generated the chr1_CFH_region.txt file. </p> <ul> <li>Open the locuszoom webpage: http://locuszoom.org/genform.php?type=yourdata</li> <li>Upload the text file (final.MD.assoc.assoc.adjusted)</li> <li>Set The P-Value column name to be \"GC\"</li> <li>Set the Marker column name to be \"SNP\"</li> <li>In the region section, enter the most associated snp (\u201crs1065489\u201d) with a flanking size of 500KB</li> <li>In the Genome Build/LD Population field select the appropriate hg19 european ref panel.</li> <li>Then press \"Plot Data\" to generate your plot.</li> </ul>"},{"location":"microbiome/","title":"Microbiomes Practical","text":"<p>Bacterial vaginosis (BV) is a dysbiotic condition caused by excessive growth of certain bacteria replacing the regular vaginal microbiome. Common symptoms include increased discharge, burning with urination, and itching. BV increases the risk of infection by a number of sexually transmitted infections including HIV/AIDS as well as the risk of early delivery when pregnant. The changed composition of the microbiome leads to a higher pH and a hundred to thousand-fold increase in the total number of bacteria present.</p>"},{"location":"microbiome/#getting-the-data","title":"Getting the data","text":"<p>To get the latest version of the data for this practical please open up a terminal window and enter the following:</p> <pre><code>bash &lt;(curl -Ssk https://tbdr.lshtm.ac.uk/static/microbiome_data.sh)  \n</code></pre> <p>For this practical we are considering 12 samples of vaginal swab that were taken at a polyclinic by a GP in a setting of high transmission of HIV. DNA was extracted from the swabs and amplified using primers specific for the first two hypervariable regions (V1 and V2) of the 16S rRNA gene (27F and 338R). These samples were then sequenced with MiSeq Illumina producing paired end data of 300 bp length per read. The 12 pairs of files generated are found in the Module6/fastq/ directory. The patients\u2019 phenotype was determined by the doctors at the time of sample collection with the following results:</p> Sample BV pH BB_1 no 4.4 BB_2 no 3.6 BB_3 yes 5.5 BB_4 no 5.3 BB_5 yes 5.6 BB_6 yes 5.3 BB_7 yes 4.7 BB_8 no 4.4 BB_9 no 4.4 BB_10 no 3.6 BB_11 yes 4.7 BB_12 yes 5"},{"location":"microbiome/#analysing-the-microbiome-samples-with-qiime2","title":"Analysing the microbiome samples with QIIME2","text":"<p>Out of all tookits aiming at the unification of the analysis of microbiome data, QIIME (pronounced \"chime\") and its successor QIIME2 have grown the largest user base in recent years (mostly due to the ease of use and comprehensive online documentation). QIIME2 wraps an extensive suite of third party tools (covering most of the \"standard\" microbiome pipeline from preprocessing and filtering of raw sequencing reads to statistical tests on diversity metrics and analyses on differential abundance of single taxa) into a single command line interface. In addition, it also provides a GUI as well as a python API for both less and more technically inclined users. We will stay on the middle ground by using the CLI today. One idiosyncrasy of QIIME2 is the use of so-called \"artefacts\". These are zip-archives with a special file extension (.qza for data artefacts and .qzv for visualisation artefacts) that hold bulk data in addition to unique IDs and provenance metadata, which describe all steps that lead to the creation of that particular artefact. This has the advantage that for every intermediate or final result of qiime it is perfectly clear how it was generated from start to finish. There is a small downside, though, since we have to import our data into the QIIME2 format prior to running any analyses. However, before we do that, let's have a look at the quality of our reads (qiime also provides functionality for sequencing data quality control, but it is not as detailed as the output of some dedicated tools like FastQC). </p>"},{"location":"microbiome/#quality-control","title":"Quality control","text":"<p>After activating the conda environment for this practical with <code>conda activate microbiome</code>, go into the module directory with <code>cd ~/Module6/</code> and have a look at its contents with <code>ls</code>. There should be a directory with the 16S sequencing data (in fastq), a 16S database (in db), and a CSV file with our metadata. Let's check if our reads are there with <code>ls fastq</code>. We can also have a look at the filesizes with <code>du -sh fastq/* | sort -h</code> (it can't hurt to get a feeling for these things). </p> <pre><code>mkdir fastqc_reports\n\nfastqc -o fastqc_reports -q -t 1 fastq/*\n</code></pre> <p>Info</p> <p>The -t flag tells fastqc the number of threads to use. If you have more CPUs available, adjust this number accordingly. </p> <p>This should produce a FastQC report for each fastq file and put them all into fastqc_reports (run <code>ls fastqc_reports</code> to double check). Going through 24 FastQC reports (two per sample; one for the forward and one for the reverse reads) manually would be quite tedious. Thankfully, multiqc can combine them for us! Let's create a new directory for it to write the results into and run it. </p> <pre><code>mkdir fastqc_combined\n\nmultiqc -o fastqc_combined fastqc_reports\n</code></pre> <p>With <code>ls fastqc_combined</code> you can see that an HTML file, which we can view in a browser, has been created.</p> <p>Scroll through the report and make note of the sequence counts barplots and the quality histograms. </p> <p></p> <p></p> <p>In the counts plot we can see that two samples (BB_3 and BB_8) have significantly fewer reads than the others. This looks like something went wrong during library preparation for these two samples and we should exclude them from further analysis. Also note that the reads of the other samples have decent quality up until ~200 bp length. We will need this information later. </p> <p>Question</p> <p>The difference in file sizes of the sequencing files between BB_3 / BB_8 and the other samples was not as drastic as the difference in actual read counts. Can you think of a reason why that might be? Hint: What does the file extension .gz mean? </p> <p>For this dataset, the primers have already been trimmed from the reads and the FastQC output showed us that there are no adapters that would need removal. Also, quality-based trimming is discouraged when using DADA2 (an important step in our later analyses). Therefore, no further pre-processing is needed and we can transform the data into the qiime format. </p>"},{"location":"microbiome/#import-into-qiime","title":"Import into qiime","text":"<p>In order to do this, qiime needs a tab-separated file with the sample IDs and the absolute paths to the forward and reverse reads. There are many ways to create such a file (and if you have just a few samples you can simply type it by hand). We will use the opportunity to string a few handy command line utilities together that we have not seen so far. First, let's write the header line of the import-list to a new file: </p> <pre><code>printf \\\n    \"sample-id\\tforward-absolute-filepath\\treverse-absolute-filepath\\n\" \\\n    &gt; fastq_abs_paths\n</code></pre> <p>Info</p> <p>We use backslashs here to break this command into multiple lines. </p> <p>Then, we append the lines corresponding to our samples to the file that was just created. We can achieve this with </p> <pre><code>ls fastq | grep -oE 'BB_[0-9]+' | sort -t _ -k 2 -n | uniq | \\\n      grep -vE 'BB_[38]' | \\\n      awk -v path=$(pwd)/fastq/ 'OFS=\"\\t\" \\\n          {print $1, path $1 \"_1.fastq.gz\", path $1 \"_2.fastq.gz\"}' \\\n      &gt;&gt; fastq_abs_paths\n</code></pre> <p>Info</p> <p>With the first grep we get the sample IDs from the filenames. We then sort them numerically (-n) based on the second field (-k 2) when split at underscores (-t _). Since there are two files per sample, we only keep the uniq sample IDs before removing the low-read-counts samples (BB_3 and BB_8) with another grep (grep -v keeps all lines that do not match the regex). The remaining sample IDs are subsequently fed to awk in order to print the absolute paths which are finally appended to fastq_abs_paths. </p> <p>This should have done the trick. <code>cat fastq_abs_paths</code> let's us see what we got. The output should look like this: </p> <pre><code>sample-id       forward-absolute-filepath       reverse-absolute-filepath\nBB_1    /home/centos/Module6/fastq/BB_1_1.fastq.gz      /home/centos/Module6/fastq/BB_1_2.fastq.gz\nBB_2    /home/centos/Module6/fastq/BB_2_1.fastq.gz      /home/centos/Module6/fastq/BB_2_2.fastq.gz\nBB_4    /home/centos/Module6/fastq/BB_4_1.fastq.gz      /home/centos/Module6/fastq/BB_4_2.fastq.gz\nBB_5    /home/centos/Module6/fastq/BB_5_1.fastq.gz      /home/centos/Module6/fastq/BB_5_2.fastq.gz\nBB_6    /home/centos/Module6/fastq/BB_6_1.fastq.gz      /home/centos/Module6/fastq/BB_6_2.fastq.gz\nBB_7    /home/centos/Module6/fastq/BB_7_1.fastq.gz      /home/centos/Module6/fastq/BB_7_2.fastq.gz\nBB_9    /home/centos/Module6/fastq/BB_9_1.fastq.gz      /home/centos/Module6/fastq/BB_9_2.fastq.gz\nBB_10   /home/centos/Module6/fastq/BB_10_1.fastq.gz     /home/centos/Module6/fastq/BB_10_2.fastq.gz\nBB_11   /home/centos/Module6/fastq/BB_11_1.fastq.gz     /home/centos/Module6/fastq/BB_11_2.fastq.gz\nBB_12   /home/centos/Module6/fastq/BB_12_1.fastq.gz     /home/centos/Module6/fastq/BB_12_2.fastq.gz\n</code></pre> <p>Great! This should be sufficient to let QIIME2 know where the files that we want to import are. Now, we can import the reads with </p> <pre><code>qiime tools import \\\n    --type 'SampleData[PairedEndSequencesWithQuality]' \\\n    --input-path fastq_abs_paths \\\n    --output-path fastq_imported.qza \\\n    --input-format PairedEndFastqManifestPhred33V2\n</code></pre> <p>This hopefully finishes successfully in a few seconds. Afterwards, you can check whether a new file was created with <code>ls</code> (which is slowly becoming our best friend now \u2013 right after <code>cd</code> of course). </p> <p>qiime also requires the metadata to be in TSV (tab-separated values), whereas our file is a CSV (comma-separated). We can simply fix this with </p> <pre><code>cat meta.csv | tr ',' '\\t' &gt; meta.tsv\n</code></pre>"},{"location":"microbiome/#denoising-with-dada2","title":"Denoising with DADA2","text":"<p>Now that we have imported the data we can unleash the power of qiime! Sequence denoising (or OTU clustering) is the centrepiece of every 16S pipeline. We will use the DADA2 which fits a sequencing error model to the data and tries to merge (\"denoise\") sequences that differ only due to sequencing errors as opposed to actual biological variation. </p> <pre><code>qiime dada2 denoise-paired \\\n    --i-demultiplexed-seqs fastq_imported.qza \\\n    --p-trunc-len-f 190 \\\n    --p-trunc-len-r 190 \\\n    --p-n-threads 1 \\\n    --verbose \\\n    --o-table table.qza \\\n    --o-representative-sequences rep_seqs.qza \\\n    --o-denoising-stats denoising_stats.qza\n</code></pre> <p>This will produce an artefact holding a list of unique sequences (rep_seqs.qza) as well as a table with the number of occurrences of each representative sequence per sample (table.qza). DADA2 fits the error model on all reads of a sequencing run simultaneously (as opposed to Deblur, which fits it separately for each sample). It is therefore considerably slower and we will have to wait a few minutes for it to finish. In the meantime you can have a look at the later sections of the practical. </p> <p>Info</p> <p>If applicable, increase the number of threads in order to speed things up. Hint: You can put time in front of any command to see how long it took. Try it with <code>time sleep 5</code> in a new terminal. Also note that we told the program to truncate forward and reverse reads after 190 bp due to the decrease in quality we saw in multiqc_report.html. As the amplicon is only expected to be ~310 bp long, this should still give us sufficient overlap. </p>"},{"location":"microbiome/#building-a-tree","title":"Building a tree","text":"<p>qiime includes a tree-building pipeline which allows us to generate a phylogenetic tree from the denoised sequences with a single command. MAFFT is used for the alignment and multiple tree-inference methods are available (have a look at qiime's phylogeny plugin for details). We will use FastTree, which is the fastest but also least accurate option available. </p> <pre><code>qiime phylogeny align-to-tree-mafft-fasttree \\\n    --i-sequences rep_seqs.qza \\\n    --o-alignment aligned_rep_seqs.qza \\\n    --o-masked-alignment masked_aligned_rep_seqs.qza \\\n    --o-tree unrooted_tree.qza \\\n    --o-rooted-tree rooted_tree.qza\n</code></pre> <p>As you can see, this will create an alignment, mask locations that aligned badly, and then generate the tree (unrooted and rooted at midpoint). </p> <p>Info</p> <p>We have built a new tree here because the pipeline with FastTree runs quite quickly and we don't want to have to wait during the practical. However, instead of creating one from scratch, we could have also inserted our sequences into an existing phylogeny. qiime offers pre-computed trees for two popular 16S databases and an insertion algorithm in the fragment-insertion plugin. In general, it needs to be said that phylogenomics is an incredibly deep topic. Since the tree is not substantial for our analysis, we can simply use qiime's pipeline with the default parameters. However, if you ever rely on a high-quality phylogeny for a different project, you should definitely try to find the best approach for your data and have a close look at the respective literature. </p>"},{"location":"microbiome/#estimating-diversity","title":"Estimating diversity","text":"<p>One reason for generating a phylogeny in a microbiome analysis is so that it can be used in phylogeny-based diversity metrics. Let's generate these now. Before we can run the corresponding command, though, we need to look up the lowest number of denoised reads per sample. </p> <p>Info</p> <p>Large differences in sequencing depth between samples can distort the results of diversity estimates. Therefore, it is common practice to down-sample (in ecology-speech \"rarify\") the reads of each sample to a number that is equal or smaller than the number of reads in the least deeply sequenced sample. This simply means that we randomly select N reads from each sample where N is the smallest number of reads in any sample. </p> <p>To check the number of denoised reads per sample, we can create a qiime visualisation of our counts table with </p> <pre><code>qiime feature-table summarize \\\n    --i-table table.qza \\\n    --o-visualization table.qzv\n</code></pre> <p>Visualisation files are produced by certain qiime commands and provide human-readable information like plots, tables, or summary statistics. There are several ways to view such files. The easiest one is to go to https://view.qiime2.org/ and drag &amp; drop them into your browser window. </p> <p>Note that the tables and plots generated at https://view.qiime2.org/ are all rendered in your local browser and that nothing is uploaded to be processed on an external server, which is often required when working with sensitive data. </p> <p>Try using this site to view the table.qzv visualisation artefact produced by the last command. Once the visualisation has loaded, there should be a table looking like this: </p> <p></p> <p>So, we need to rarify to a sampling depth of 24,336 reads. Let's generate the diversity metrics now (again, adjust the number of threads according to your setup): </p> <pre><code>qiime diversity core-metrics-phylogenetic \\\n    --i-phylogeny rooted_tree.qza \\\n    --i-table table.qza \\\n    --p-sampling-depth 24366 \\\n    --p-n-jobs-or-threads 1 \\\n    --m-metadata-file meta.tsv \\\n    --output-dir core-metrics-results\n</code></pre> <p>This will generate a new directory \"core-metrics-results\" holding (based on multiple different diversity metrics) sample-wise diversity values (\"alpha diversity\"), pairwise inter-sample distance matrices (\"beta diversity\"), and visualisations of PCoA plots (ending in .qzv). These can again be inspected with https://view.qiime2.org/. For example, the PCoA plot based on Bray\u2013Curtis distance with BV-negative samples in red and BV-positive samples in blue looks like this: </p> <p></p> <p>Question</p> <p>What does the plot tell us about our samples and the impact of BV on inter-sample diversity. Look up the term \"Anna Karenina Principle\" and what it means in terms of the microbiome. Can we say that it applies to our data? </p>"},{"location":"microbiome/#taxonomic-classification","title":"Taxonomic classification","text":"<p>We are not only interested in the ecological diversity of our samples; we also want to know which species were found. Again, there are multiple ways of achieving this. We will use a Na\u00efve Bayes classifier (pre-trained on the Greengenes 13_8 database) available from the Qiime2 website. You can find it in the db directory and use it with the following command: </p> <pre><code>qiime feature-classifier classify-sklearn \\\n    --i-classifier db/gg-13-8-99-nb-classifier.qza \\\n    --i-reads rep_seqs.qza \\\n    --p-n-jobs 1 \\\n    --o-classification taxonomy.qza\n</code></pre> <p>The produced table in taxonomy.qza simply links the taxonomic classifications (from phylum to species level) to the corresponding sequences. If you want to inspect the table, run </p> <pre><code>qiime metadata tabulate \\\n    --m-input-file taxonomy.qza \\\n    --o-visualization taxonomy.qzv\n</code></pre> <p>and open the visualisation taxonomy.qzv in https://view.qiime2.org/. </p> <p>To get a more intuitive understanding of the microbial composition of our samples we can now ask qiime to plot it for us: </p> <pre><code>qiime taxa barplot \\\n    --i-table table.qza \\\n    --i-taxonomy taxonomy.qza \\\n    --m-metadata-file meta.tsv \\\n    --o-visualization taxa_barplot.qzv\n</code></pre> <p>The resulting visualisation at species level (\"Level 7\") looks like this in https://view.qiime2.org/: </p> <p></p> <p>Info</p> <p>You can adjust the with of the bars with the slider above the plot. </p> <p>Question</p> <p>We can see that some samples are dominated by Lactobacillus iners (green), whereas for others the situation looks very different. Double check with the metadata to find out if this is associated with BV-status. </p>"},{"location":"microbiome/#testing-differences-in-alpha-diversity","title":"Testing differences in alpha diversity","text":"<p>Alpha diversity measures the general diversity of an ecosystem (i.e. a sample in our case) or a group of ecosystems (i.e. groups of samples like all samples with BV). After looking at the taxa barplot we just generated, do you think that the BV samples are statistically significantly more diverse than the non-BV samples? We can check if your estimate is correct by running a Kruskal\u2013Wallis test on the four metrics of alpha diversity that we calculated for our samples. Let's create a new directory to write the results into and run: </p> <pre><code>mkdir alpha_tests\nfor metric in faith_pd evenness shannon observed_features; do\n    qiime diversity alpha-group-significance \\\n        --i-alpha-diversity core-metrics-results/${metric}_vector.qza \\\n        --m-metadata-file meta.tsv \\\n        --o-visualization alpha_tests/${metric}_group_significance.qzv\ndone\n</code></pre> <p>This produces four more visualisations. Have a look at them. Were you right? </p> <p>Question</p> <p>It looks like the different alpha diversity metrics disagree! After reading the short definitions of the metrics provided below, can you think of a reason for this discrepancy? faith_pd: Faith's phylogenetic diversity is defined as the sum of branch-lengths in the phylogeny between all species found in a sample (regardless of abundance). evenness: Pielou's evenness index quantifies how differently abundant species making up an ecosystem are. shannon: The Shannon index or Shannon entropy quantifies how difficult it is to guess the species of a random specimen taken from the sample (the more species and the more equally abundant they are, the more difficult). observed_features: Simply the number of unique taxa found in the sample. </p>"},{"location":"microbiome/#testing-beta-diversity","title":"Testing beta diversity","text":"<p>As opposed to alpha diversity, which quantifies the diversity of a sample (or a group of samples) overall, beta diversity gives an estimate of the magnitude of differences between individual samples or groups of samples. We can test the difference between BV and non-BV samples for all beta diversity metrics with the following command: </p> <pre><code>mkdir -p beta_tests\n\nfor metric in bray_curtis jaccard unweighted_unifrac weighted_unifrac; do\n    qiime diversity beta-group-significance \\\n        --i-distance-matrix core-metrics-results/${metric}_distance_matrix.qza \\\n        --m-metadata-file meta.tsv \\\n        --m-metadata-column BV \\\n        --o-visualization beta_tests/${metric}_significance.qzv \\\n        --p-permutations 9999\ndone\n</code></pre> <p>Again, we got a visualisation for each metric. Have a look at them in https://view.qiime2.org/. What do you find? Are all of them in agreement this time? </p> <p>This concludes today's practical. If you are interested in differentially abundant taxa between the BV and non-BV samples, have a look at qiime's' ANCOM function. </p> <p>Acknowledgements: Many thanks to Dr. Suzanna Francis for providing the data and Ernest Diez-Benavente and Julian Lisebber-Egger for designing the practical materials.</p>"},{"location":"transcriptomics/","title":"Transcriptomics","text":""},{"location":"transcriptomics/#introduction","title":"Introduction","text":"<p>An application of next-generation sequencing is RNA sequencing (Mortazavi et al., 2008; Wang et al., 2009). In particular we will discuss transcriptome (messenger RNA) sequencing. Transcriptome sequencing is a very useful addition to genome sequencing projects as it helps to identify genes and thus aids in genome annotation. In this sense, it is similar to earlier transcriptome sequencing using capillary methods (EST sequencing), but provides much higher coverage of the transcriptome.</p> <p>Reads from RNA sequencing can be treated in much the same way as those from DNA sequencing. The exception is in eukaryotes when there is splicing, where a single gene can code for multiple proteins through transcription of determined exons.</p> <p>Due to the vast number of reads produced by next generation sequencing technology, the transcriptome is also sequenced very deeply. Each gene is sequenced in proportion to its abundance and the large number of reads means that even low abundance genes are sequenced to some extent. This means that expression levels of genes can be compared. One can visualise the \"pile up\" of reads in a particular region by looking at coverage plots. The higher the signals in the plot, the more expressed a transcript is. It is important to note that the sequences originate from transcriptome samples (mRNA) and therefore only contains information about the exons and untranslated regions (UTRs).</p> <p>Imagine the following transcript is present in the sample:</p> <p></p> <p>Reads belonging to the transcript are produced by the sequencing process. When the reads come out as raw data, there is no information about where they belong in the reference genome. Furthermore, all reads from several different transcripts come out together. An alignment algorithm localises them in the reference genome based on similarity matches.</p> <p></p> <p>In the plot, the coverage line represents the number of reads that align to the genome at each base position. This allows us to identify coding regions, here, the 3 exons (in yellow) that comprise the transcript above.</p> <p>In this module we will use a similar approach used to map DNA sequencing data to map RNA sequencing data from Mycobacterium tuberculosis.</p> <p>Understanding an organism's genome goes beyond cataloging the genes that are present in the genome. Insight into the biological stages in which each gene is expressed (potentially used) helps us to identify how organisms develop and respond to a particular external stimuli. The first layer of such complex patterns involves the understanding of how the genome is being used is the transcriptome. This is also the most accessible type of information because, like the genome, the transcriptome is made of nucleic acids and can be sequenced relatively easily. Arguably the proteome is of greater relevance to understand cellular biology, but it is chemically heterogenous making it much more difficult to assay.</p> <p>Over the past two decades, microarray technology has been applied extensively for addressing the question of which genes are expressed and when, enabling the performance of differential expression analysis. Despite its success, this technology is limited in that it requires prior knowledge of the gene sequences for an organism and has a limited dynamic range in detecting the level of expression, e.g. how many copies of a transcript are made. RNA sequencing technology using, for instance Illumina HiSeq machines, can sequence all the genes that are transcribed, and the results have a more linear relationship to the real number of transcripts generated.</p> <p>The aim of differential expression analysis is to determine which genes are more or less expressed in different situations. We could ask, for instance, whether a bacterium uses its genome differentially when exposed to stress, such as heat or challenged by a drug. Alternatively, we could ask which genes make human livers different from kidneys.</p> <p>In these exercises, we will try to gain some understanding of differences between M. tuberculosis lineages. The genome of M. tuberculosis was published in 1998 (Cole et al., 1998). It has 4.4 Mb and a high GC content (~65%), comprising 4,111 genes. Although the variability of the M. tuberculosis genome has been considered limited, it has been demonstrated a higher diversity than it was previously thought. Currently, M. tuberculosis is classified in 7 different lineages with a different geographical distribution, and also virulence or spreading capacity has been seen to vary between lineages. Strains from different lineages have shown differences in virulence or in acquisition of drug resistance (Parwati et al., 2010), and these differences might be caused by variable expression of determined genes.</p> <p>Therefore, the aim of this session is to become familiar with the steps carried out in transcriptomics studies, from mapping RNA-seq reads to the performance of differential expression analysis.</p>"},{"location":"transcriptomics/#exercise-1-mapping-rna-seq-with-bwa","title":"Exercise 1: Mapping RNA-seq with BWA","text":"<p>First, we will map RNA sequence reads from a M. tuberculosis lineage 1 strain to the reference genome, in this case, the H37Rv M. tuberculosis strain.</p> <p>You can find the M. tuberculosis H37Rv reference genome (called H37Rv.fa) as well as the two files of RNA-seq reads from a lineage 1 strain (Mtb_L1_1.fastq and Mtb_L1_2.fastq) in the transcriptomics directory.</p>"},{"location":"transcriptomics/#running-bwa","title":"Running BWA","text":"<p>To work with the command line of Linux, you will first need to open a terminal and go to the data and transcriptomics directory:</p> <pre><code>cd ~/Module5\n</code></pre> <p>And list the files there:</p> <pre><code>ls\n</code></pre> <p>You will find there the 4 fastq files, 2 of them from the lineage 1 sample, and the reference genome fasta file; these are the input data for this practical.</p> <p>For the mapping, first an index of the reference genome must be constructed with bwa index. On the command line, you should type:</p> <pre><code>bwa index H37Rv.fa\n</code></pre> <p>This will generate 5 files which are needed for BWA. We will then align the RNA-seq reads to the reference genome with bwa mem. We will therefore use the reference genome (in fasta format) and the two fastq files that contain the RNA-seq reads, saving the output to a SAM file. To start you should type:</p> <p><pre><code>bwa mem H37Rv.fa Mtb_L1_1.fastq.gz Mtb_L1_2.fastq.gz &gt; ./Mapping_Mtb/Mtb_L1.sam\n</code></pre> The output will be located in the Mapping_Mtb folder, which is in the transcriptomics directory.</p>"},{"location":"transcriptomics/#exercise-2-converting-bwa-sam-output-to-bam-and-indexing","title":"Exercise 2: Converting BWA SAM output to BAM and indexing","text":""},{"location":"transcriptomics/#sam-to-bam-using-samtools","title":"SAM to BAM using samtools","text":"<p>The details of where each M. tuberculosis read has been mapped are now stored in a file in the directory Mapping_Mtb. We are going to view the mapped reads in Artemis using the Artemis BAM view. However, the mapping result is not currently in BAM format. To make a BAM file from the BWA output we need to run a short series of programs.</p> <p>To convert the BWA output SAM file to BAM format we are going to use samtools. First, we go to the directory where the output file from the BWA is and we will transform the sam file to bam (as we are already in the Transcriptomics directory we just need to type):</p> <pre><code>cd ~/Module5/Mapping_Mtb\n\nsamtools view -b Mtb_L1.sam &gt; Mtb_L1.bam\n</code></pre> <p>Once we have the BAM file, we need to sort it and index it. To do it, we will use samtools sort and samtools index commands:</p> <pre><code>samtools sort -o Mtb_L1.sorted.bam Mtb_L1.bam\n\nsamtools index Mtb_L1.sorted.bam\n</code></pre> <p>Question</p> <p>What does the parameters -b in samtools view and -o in samtools sort mean? </p> <p>To see the list of options and parameters for the commands, type:</p> <pre><code>samtools view\n\nsamtools sort\n</code></pre> <p>Now we are going to save our sorted file as Mtb_L1.bam and Mtb_L1.bam.bai for the index one.</p> <pre><code>mv Mtb_L1.sorted.bam Mtb_L1.bam\n\nmv Mtb_L1.sorted.bam.bai Mtb_L1.bam.bai\n</code></pre> <p>The resulting bam and index files will then be in the folder Mapping_Mtb. The alignment output could now be visualised in Artemis, Tablet or a visualisation tool of your choice.</p> <p>Info</p> <p>The steps outlined above show how to go from a fastq file to a sorted bam file. Though we have asked you to run the steps individually, they can be combined into one line. Don't run this line! This is just for your information. <pre><code>bwa mem H37Rv.fa Mtb_L1_1.fastq.gz Mtb_L1_2.fastq.gz | samtools sort --write-index -o ./Mapping_Mtb/Mtb_L1.bam - \n</code></pre> All samtools commands can take input as sam, bam or cram and converts to bam for internal use. We can therefor directly pipe the sam output to samtools sort and store the sorted output in bam. </p>"},{"location":"transcriptomics/#exercise-3-visualisation-of-the-bam-files","title":"Exercise 3: Visualisation of the BAM files","text":"<p>Now we will examine the reads mapping in Artemis using the BAM view feature.</p>"},{"location":"transcriptomics/#viewing-the-mapped-reads-in-artemis","title":"Viewing the mapped reads in Artemis","text":"<p>Open Artemis (type art in the terminal) and select: 'File', 'Open Project Manager', select '+' to add a new project you can call \"tb\" and load H37Rv.fa, which contains the reference genome. We need also to add the genome features, so we can see the gene models. For doing so, we will load the Mtb.gtf file (in the ~/Module5 directory) as the annotation track. Select 'annotation' and then press 'new property'.</p> <p></p> <p>Now select 'open' and the artemis window should appear. From the Artemis 'File' menu, select 'Read BAM/VCF', and then select the bam file you just generated from the L1 Mtb sample (i.e. Mtb_L1.bam).</p> <p>You should see the BAM window appear (shown in the screen shot below). We want to change the view in order to better see how the reads map to the genome.</p> <p></p>"},{"location":"transcriptomics/#interpreting-the-mapping","title":"Interpreting the mapping","text":"<p>This exercise is similar to the one performed before in the Visualisation module. Scroll along the genome and examine the read coverage (the part of the genome mapped goes from position 2420631 to 2920631. To view that part select 'Goto', 'Navigator' and write in 'Goto Base' 2420631). Notice how different genes have different depths of coverage.</p> <p>Question</p> <p>Why do some genes have little or no coverage?</p> <p>Why do some reads map where there are no genes?</p> <p></p>"},{"location":"transcriptomics/#including-more-lineages","title":"Including more lineages","text":"<p>One interesting feature of the Artemis viewer is the possibility to see more than one BAM file at the same time, which enables to comapre coverage from different samples. Hence, next we want to include more lineages, in this case we will add another sample belonging to the lineage 4 of Mtb.</p> <p>To do it, we will need first to follow the previous steps in order to get the sorted and index bam files. Therefore, map it with BWA as before, the fastq files are in the directory ~/Module5 and are called Mtb_L4_1.fastq.gz and Mtb_L4_2.fastq.gz. You can try with the one-line code!</p> <p>Once we have the bam files, we can add it to the viewer.</p> <p></p> <p>In the BAM view of the reads, it might be difficult to distinguish the differences between the BAM files. However, in the coverage plot, one can see the differences in coverage.</p> <p>One reason to perform RNA-seq under different conditions or in different samples (in this case different lineages of Mtb), is to see genes that are differentially expressed. For example, one gene may be more highly expressed in one lineage that in the other.</p> <p>Question</p> <p>Can you find any genes that have differential expression?</p> <p></p> <p>Now go to gene Rv2161c (position 2422271).</p> <p></p> <p>Question</p> <p>Would you think that this gene is differentially expressed?</p>"},{"location":"transcriptomics/#exercse-4-differential-expression","title":"Exercse 4: Differential expression","text":"<p>There are tools that calculate the differential expression, like the R packages DESeq or EdgeR. They take the reads mapped to each gene, normalize the resulting quantities of mapped reads (coverage), and then estimate if any genes are differentially expressed. In general, the results are more credible and significant if biological replicates are included.</p>"},{"location":"transcriptomics/#counting-reads-with-htseq-count","title":"Counting reads with HTSeq-count","text":"<p>In order to perform a differential expression analysis, the first step is to count the reads mapped to each of the genes so that we can make comparisons between the different samples.</p> <p>HTSeq-count is part of the HTSeq package which will quantify the number of reads mapping to gene models in different RNA-seq experiments given a file with aligned sequencing reads (the bam file obtained through BWA) and a list of genomic features (the Mtb.gtf file with the gene annotation).</p> <p>We will run HTSeq-count with the RNA-seq data from the L1 and L4 strains we were using in the previous exercises. To do it, we will go to the directory where we have the data and use the following command:</p> <pre><code>cd ~/Module5\n\npython -m HTSeq.scripts.count -f bam -r pos -s reverse -t gene ./Mapping_Mtb/Mtb_L1.bam Mtb.gtf &gt; ./Mapping_Mtb/Mtb_L1_htseq_count.txt\n\npython -m HTSeq.scripts.count -f bam -r pos -s reverse -t gene ./Mapping_Mtb/Mtb_L4.bam Mtb.gtf &gt; ./Mapping_Mtb/Mtb_L4_htseq_count.txt\n</code></pre> <p>The parameters we have used in the HTSeq-count command are:</p> <ul> <li>-f: format of the input data</li> <li>-r: how is sorted the data</li> <li>-s: whether the data is from a strand-specific assay. The reverse option is used for pair-end reads from HiSeq in order to mantain the strain-specificity (the reads have to map to the gene in the corresponding strand to be counted)</li> <li>-t: feature type, in this case exon</li> </ul> <p>If you have any doubt about the parameters of the program, type:</p> <pre><code>python -m HTSeq.scripts.count\n</code></pre> <p>Question</p> <p>What would -a parameter do?</p> <p>We can now take a look at the results from the HTSeq-count typing the following in the command line:</p> <pre><code>cd ~/Module5/Mapping_Mtb\n\nless Mtb_L1_htseq_count.txt\n</code></pre> <p>You should see two columns with the list of genes and the counts for each gene.</p> <p>Output</p> <pre><code>Rv2158c 0\nRv2159c 22\nRv2160A 11\nRv2160c 0\nRv2161c 193\nRv2162c 753\nRv2163c 6181\nRv2164c 2169\nRv2165c 6878\nRv2166c 11357\nRv2167c 0\nRv2168c 0\nRv2169c 3017\nRv2170  235\nRv2171  1779\nRv2172c 9812\nRv2173  1525\nRv2174  1828\nRv2175c 767\nRv2176  1440\nRv2177c 169\nRv2178c 6200\nRv2179c 205\nRv2180c 319\nRv2181  4288\nRv2182c 10635\nRv2183c 1197\n:\n</code></pre> <p>To exit this view you just need to type 'q'.</p>"},{"location":"transcriptomics/#finding-differentially-expressed-genes-with-deseq2","title":"Finding differentially expressed genes with DESeq2","text":"<p>Now we are going to perform a differential expression analysis in order to look for genes with variable expression between lineages. To do it we will use 6 sequenced samples, 3 from lineage 1 and 3 from lineage 4. Two of them will be the two analysed in the previous steps. We are going to use an R package for the anaylsis of the differential gene expression called DESeq2.</p> <p>A differential expression analysis is used to compare gene expression levels, given by the number of reads per gene (obtained by HTSeq-count) between samples (for example, between 2 lineages of Mtb). In order to accurately ascertain which genes are differentially expressed, and the amount of expression, it is necessary to use replicated data. As with all biological experiments doing it once may simply not be enough. There is no simple way to decide how many replicates to do, it is usually a compromise of statistical power and cost. By determining how much variability there is in the sample preparation and sequencing reactions we can better assess whether genes are really expressed and more accurately determine any differences. The key to this is performing biological rather than technical replicates. This means, for instance in tuberculosis, growing up three cultures of bacteria, treating them all identically, extracting RNA from each and sequencing the three samples separately. Technical replicates, whereby the same sample is sequenced three times do not account for the variability that really exists in biological systems or the experimental error between cultures of bacteria and RNA extractions. More replicates will help to improve statistical power for genes that are already detected at high levels, while deeper sequencing will improve power to detect differential expression for genes which are expressed at low levels. In this exercise we will consider the 3 L1 and the 3 L4 samples as biological replicates.</p> <p>To start, we firstly need a table with the counts. In the Mapping_Mtb directory (where we should be) we can find a folder called HTSeqCounts with 6 files called:</p> <pre><code>cd ~/Module5/Mapping_Mtb/HTSeqCounts\n\nls\n</code></pre> <p>Output</p> <pre><code>Mtb_1_L4_htseq_count.txt  Mtb_3_L1_htseq_count.txt  Mtb_5_L1_htseq_count.txt\nMtb_2_L1_htseq_count.txt  Mtb_4_L4_htseq_count.txt  Mtb_6_L4_htseq_count.txt\n</code></pre> <p>Now, to start, we need to open R in the terminal, just typing:</p> <pre><code>R\n</code></pre> <p>And then load the packages we are going to need for the analysis:</p> <pre><code>library(DESeq2)\nlibrary(gplots)\n</code></pre> <p>These 6 files are the results of the HTSeq-count of the two samples previously analysed plus 4 more Mtb samples we will use to perform the analysis.</p> <p>To prepare the data we are going to use the following scripts.</p> <p>First we are going to set the directory where we have the files:</p> <pre><code>directory &lt;- \"~/Module5/Mapping_Mtb/HTSeqCounts/\" \n</code></pre> <p>And now we can select the files and save them in the variable \u2018sampleFiles\u2019 by selecting all the files that contain \"Mtb\" that are present in our directory:</p> <pre><code>sampleFiles &lt;- grep(\"Mtb\", list.files(directory), value = TRUE)\n</code></pre> <p>As we are comparing lineage 1 to lineage 4 samples, we are going to set up lineage as \"condition\".</p> <pre><code>sampleCondition &lt;- c(\"l4\",\"l1\",\"l1\",\"l4\",\"l1\",\"l4\")\n</code></pre> <p>Now we construct the table with the sample information and convert it in a DESeq object:</p> <pre><code>sampleTable &lt;- data.frame(\n    sampleName = sampleFiles,\n    fileName = sampleFiles,\n    condition = sampleCondition\n)\n\ndds &lt;- DESeqDataSetFromHTSeqCount(\n    sampleTable = sampleTable,\n    directory = directory,\n    design = ~ condition\n)\n</code></pre> <p>Before doing the analysis, we are going to filter the dataset keeping only the genes with at least 10 counts, so that we make sure that every gene considered for the analysis was transcribed.</p> <p>To do it, type the following:</p> <pre><code>keep &lt;- rowSums(counts(dds)) &gt;= 10\ndds &lt;- dds[keep,]\n</code></pre> <p>And we are going to set up the condition for the analysis in two levels which are 'lineage 1' and 'lineage 4':</p> <pre><code>dds$condition &lt;- factor(dds$condition, levels = c(\"l1\",\"l4\"))\n</code></pre> <p>We can then run the differential expression anaylisis by calling the function DESeq(), which will normalise the data and compare between the two groups established (l1 and l4). We can store the results in a variable called 'res':</p> <pre><code>dds &lt;- DESeq(dds)\nres &lt;- results(dds)\n</code></pre> <p>Let's take a look at the results. Type:</p> <pre><code>res\n</code></pre> <p>And you should get a table like this:</p> <p>Output</p> <pre><code>log2 fold change (MLE): condition l4 vs l1\nWald test p-value: condition l4 vs l1\nDataFrame with 441 rows and 6 columns\n        baseMean log2FoldChange     lfcSE       stat       pvalue         padj\n\nRv2159c 1251.0885      6.5961892 0.5609037  11.759933 6.278432e-32 9.208368e-30\nRv2160A  766.1015      6.6738839 0.5544491  12.036965 2.271613e-33 4.997548e-31\nRv2161c 5336.3523      5.8122020 0.4210642  13.803600 2.424369e-43 1.066722e-40\nRv2162c 4784.6386      3.8915692 0.3784335  10.283364 8.375204e-25 9.212724e-23\nRv2163c 3616.8513     -0.5480522 0.3940154  -1.390941 1.642434e-01 9.243213e-01\n...           ...            ...       ...        ...          ...          ...\nRv2586c  3828.546     0.16674016 0.3612166  0.4616071    0.6443631    0.9964280\nRv2587c  5655.191     0.21607557 0.3636699  0.5941530    0.5524098    0.9964280\nRv2588c  1305.013    -0.02030647 0.4871420 -0.0416849    0.9667499    0.9983353\nRv2589   1665.930     0.25845265 0.3629410  0.7121064    0.4763989    0.9964280\nRv2590   5873.482     0.42707857 0.6169747  0.6922141    0.4888029    0.9964280\n</code></pre> <p>The first column represents the name of each gene analysed, which are represented in rows.</p> <p>Question</p> <p>How many genes did we analyse?</p> <p>Let's take a look at the summary of the results we just obtained:</p> <pre><code>summary(res)\n</code></pre> <p>Output</p> <pre><code>out of 441 with nonzero total read count\nadjusted p-value &lt; 0.1\nLFC &gt; 0 (up)     : 10, 2.3%\nLFC &lt; 0 (down)   : 7, 1.6%\noutliers [1]     : 1, 0.23%\nlow counts [2]   : 0, 0%\n(mean count &lt; 2)\n[1] see 'cooksCutoff' argument of ?results\n[2] see 'independentFiltering' argument of ?results\n</code></pre> <p>When asking whether a gene is differentially expressed we use statistical tests to assign a p-value. If a gene has a p-value of 0.05 we know that there is only a 5% chance that it is not really differentially expressed. However, if we are asking this question for every gene in the genome, then we would expect to see due to multiple comparison, p-values less than 0.05 for many genes even though they are not really differentially expressed. Due to this statistical problem we must correct the p-values so that we are not tricked into accepting a large number of erroneous results. Adjusted p-values are p-values which have been corrected for what is known as multiple hypothesis testing. </p> <p>The summary shows us the number of genes with an adjusted p-value &lt; 0.1 that are under or over expressed in one of the groups (log2FoldChange above or below 0, here represented as LFC). The adjusted p-value in the DESeq analysis is equivalent to the FDR or 'False Discovery Rate'. This value represents the proportion of discoveries that we can expect to be false.</p> <p>Question</p> <p>Which is the maximum percentage of \"false discoveries\" that we can expect given a cut off adjusted p-value of 0.1?</p> <p>How many genes are up and down-regulated with an adjusted p-value &lt; 0.1?</p> <p>Some of the p-values in our results might be NA values, which can be due to extreme outliers. To continue with the analysis we are going to remove these missing values.</p> <pre><code>res &lt;- res[!is.na(res$padj),]\n</code></pre> <p>Let's now order the results by p value, so we see the top genes with the highest statistial significance. Take a look at the results again.</p> <pre><code>resOrdered &lt;- res[order(res$pvalue),]\nresOrdered\n</code></pre> <p>To visualise the diffences in expression we are going to plot a heatmap using the 17 genes that are above the cut off. To do it, we will first get the normalised counts in a variable called \"counts_heatmap\". We will copy the names of the first 17 genes from our \"resOrdered\" table in a vector, and then extract the normalised counts from \"counts_heatmap\" for the 17 genes we want to plot.</p> <pre><code>counts_heatmap &lt;- counts(dds, normalized = TRUE)\nidx &lt;- rownames(resOrdered)[1:17]\ncounts_heatmap &lt;- counts_heatmap[rownames(counts_heatmap)%in%idx,]\n</code></pre> <p>If we type:</p> <pre><code>counts_heatmap\n</code></pre> <p>We can see the table with the normalised counts for each sample and each of the genes of our interest.</p> <p>Output</p> <pre><code>    Mtb_1_L4_htseq_count.txt Mtb_2_L1_htseq_count.txt\nRv2159c               1061.02472                16.090459\nRv2160A                933.18297                 8.045229\nRv2161c              10927.68994               141.157208\nRv2162c               8503.01996               550.732527\nRv2188c               1643.41488               495.147306\nRv2271                 804.10604              1115.361360\nRv2274A                 57.43615                68.018758\nRv2275                2069.55403              1757.516950\nRv2292c                 54.96577               263.298419\nRv2338c               1439.60920              3638.637880\nRv2346c               1742.22976              1260.175491\nRv2381c               5656.53398              1778.727101\nRv2382c               2140.57722               623.139593\nRv2493                2611.18306               308.644258\nRv2494                1635.38617               244.282423\nRv2506                 345.23447               993.220149\nRv2573                  31.49724                71.675681\n        Mtb_3_L1_htseq_count.txt Mtb_4_L4_htseq_count.txt\nRv2159c                 34.44955               3070.71886\nRv2160A                 25.05422               1716.06570\nRv2161c                122.13932              10217.41567\nRv2162c                685.85926              12248.53695\nRv2188c                595.03771               3311.94670\nRv2271                3936.64424                797.08204\nRv2274A                147.19354                 55.37080\nRv2275                3592.14872               1232.32231\nRv2292c                140.92998                 62.66773\nRv2338c               3335.34297               1310.44236\nRv2346c                908.21546               2235.00602\nRv2381c                466.63484               3045.82346\nRv2382c                654.54148               1449.94245\nRv2493                 184.77487               2647.49705\nRv2494                 266.20108               1598.45639\nRv2506                 494.82084                499.19570\nRv2573                 112.74399                 57.08773\n        Mtb_5_L1_htseq_count.txt Mtb_6_L4_htseq_count.txt\nRv2159c                 30.57068               3293.67692\nRv2160A                 16.98371               1897.27712\nRv2161c                302.31010              10307.40137\nRv2162c                577.44627               6142.23638\nRv2188c                343.07102               4986.18078\nRv2271                1837.63783                871.00738\nRv2274A                220.78828                 26.91855\nRv2275                9847.15722               1075.78064\nRv2292c                125.67948                 71.62257\nRv2338c               5896.74541               1217.10303\nRv2346c                886.54986               8732.18549\nRv2381c               1895.38245               3401.35112\nRv2382c                740.48992               1372.36538\nRv2493                 377.03844               1754.03197\nRv2494                 261.54919               1206.52789\nRv2506                1864.81177                392.72242\nRv2573                 220.78828                 49.03022\n</code></pre> <p>To plot the heatmap copy the following script:</p> <pre><code>colnames(counts_heatmap) &lt;- c(\"L4_1\",\"L1_2\",\"L1_3\",\"L4_4\",\"L1_5\",\"L4_6\")\nheatmap.2(as.matrix(counts_heatmap), scale=\"row\", col=greenred(75), Rowv=NA, dendrogram = \"col\", trace=\"none\", density.info = \"none\")\n</code></pre> <p>You should get a plot like this:</p> <p></p> <p>Question</p> <p>Do the samples cluster by lineage in the dendrogram?</p> <p>As you can see in the color key, red cells in the plot represent overexpressed genes whilst green ones the underexpressed genes. Rows represent the 17 genes of interest and columns the 6 samples we are analysing.</p> <p>Question</p> <p>How is Rv2493 in lineage 4 samples? And Rv2159c in lineage 1?</p> <p>Take a look at the first 5 genes in the plot. As you might assume by the numbers they are located in the genome one after the other. Which potential explanations would you give to their down-regulation in one of the lineages?</p>"},{"location":"transcriptomics/#further-exploration","title":"Further exploration","text":""},{"location":"transcriptomics/#what-do-i-do-with-a-gene-list","title":"What do I do with a gene list?","text":"<p>As we have just seen, differential expression analysis results is a list of genes which show differences between two conditions. It can be daunting trying to determine what the results mean. On one hand you may find that due to there being no real differences or there being too much noise in your experiment, you have no significant differences. On the other hand, you may find thousands of genes are differentially expressed. What can you say about that?</p> <p>Other than looking for genes you expect to be different or unchanged, one of the first things to do is look at Gene Ontology (GO) term enrichment. There are many different algorithms for this, but you should annotate your genes with functional terms from GO using for instance Bast2GO (Conesa et al., 2005) and then use perhaps TopGO (Alexa et al., 2006) to determine whehter any particular sorts of genes occur more than expected in your differentially expressed genes.</p>"},{"location":"transcriptomics/#references","title":"References","text":"<p>Mortazavi A, Williams BA, McCue K, Schaeffer L, Wold B. (2008). Mapping and quantifying mammalian transcriptomes by RNA-Seq. Nat Methods 5(7):621-8. doi: 10.1038/nmeth.1226</p> <p>Wang Z, Gerstein M, Snyder M. (2009). RNA-Seq: a revolutionary tool for transcriptomics. Nat Rev Genet 10(1):57-63. doi: 10.1038/nrg2484</p> <p>Cole ST, Brosch R, Parkhill J, Garnier T, Churcher C, Harris D et al. (1998). Deciphering the biology of Mycobacterium tuberculosis from the complete genome sequence. Nature 393(6685):537-44.</p> <p>Parwati I, van Crevel R, van Soolingen D. (2010) Possible underlying mechanisms for successful emergence of the Mycobacterium tuberculosis Beijing genotype strains. Lancet Infect Dis 10(2):103-111. doi: 10.1016/S1473-3099(09)70330-5</p> <p>Conesa A, Gotz S, Garcia-Gomez JM, Terol J, Talon M, Robles M. (2005) Blast2GO: a universal tool for annotation, visualization and analysis in functional genomics research. Bioinformatics 21(18):3674-6.</p> <p>Alexa A, Rahnenfuhrer J, Lengauer T. (2006). Improved scoring of functional groups from gene expression data by decorrelating GO graph structure. Bioinformatics 22(13):1600-7.</p>"}]}